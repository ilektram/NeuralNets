{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l1, l2, activity_l2\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(levelname)-8s %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "def load_data(input_data):\n",
    "    \"\"\"\n",
    "    Loads data as pandas dataframe\n",
    "    input_data: a single csv file with an ID column\n",
    "    \"\"\"\n",
    "    df_train = pd.read_csv(input_data, index_col=\"ID\")\n",
    "\n",
    "    # Fill categorical categories with NA value and convert them to the right\n",
    "    # type\n",
    "    for col in df_train.select_dtypes(include=['object']).columns:\n",
    "        df_train[col] = df_train[col].fillna(value='NA', axis=0)\n",
    "        df_train[col] = df_train[col].astype('category')\n",
    "\n",
    "    # Fill the other columns with 0 as the fill value\n",
    "    for col in df_train.select_dtypes(exclude=['category']).columns:\n",
    "        df_train[col] = df_train[col].fillna(value=-1, axis=0)\n",
    "\n",
    "    old_length = df_train.shape[0]\n",
    "    df_train = df_train.dropna(axis=0, how='any')\n",
    "    row_diff = old_length - df_train.shape[0]\n",
    "    logging.debug(\n",
    "        \"Dropped {} rows with NAs {:.1%}\".format(\n",
    "            row_diff,\n",
    "            float(row_diff)/old_length\n",
    "        )\n",
    "    )\n",
    "    return df_train\n",
    "\n",
    "\n",
    "def categorical_to_front(input_df):\n",
    "    cat_columns = list(input_df.select_dtypes(include=['category']).columns)\n",
    "\n",
    "    logging.debug(\"Number of categorical columns: {}\".format(len(cat_columns)))\n",
    "\n",
    "    other_columns = list(input_df.select_dtypes(exclude=['category']).columns)\n",
    "\n",
    "    new_column_order = cat_columns + other_columns\n",
    "    train_df = input_df[new_column_order]\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def categorical_analysis(input_data):\n",
    "    categories = []\n",
    "    for col in input_data.columns:\n",
    "        if str(input_data[col].dtype) == \"category\":\n",
    "            cat = {\n",
    "                \"col_lbl\": col,\n",
    "                \"cat_count\": input_data[col].cat.categories.shape[0]\n",
    "            }\n",
    "            categories.append(cat)\n",
    "    return categories\n",
    "\n",
    "\n",
    "def convert_category_to_columns(input_data, column_name):\n",
    "    if not isinstance(input_data, pd.DataFrame):\n",
    "        raise TypeError(\"Input data must be a Pandas DataFrame\")\n",
    "    if str(input_data[column_name].dtype) != \"category\":\n",
    "        raise RuntimeError(\"Can only run this on categorical columns\")\n",
    "    categories = input_data[column_name].cat.categories\n",
    "\n",
    "    for cat in categories:\n",
    "        new_col_name = \"{col}_{cat}\".format(col=column_name, cat=cat)\n",
    "        input_data[new_col_name] = np.where(\n",
    "            input_data[column_name] == cat,\n",
    "            1,\n",
    "            0\n",
    "        )\n",
    "\n",
    "\n",
    "def convert_categories_to_columns(input_data, cat_thres=130):\n",
    "    cols_to_remove = []\n",
    "    for col in input_data.columns:\n",
    "        if str(input_data[col].dtype) == 'category':\n",
    "            if input_data[col].cat.categories.shape[0] < cat_thres:\n",
    "                convert_category_to_columns(input_data, col)\n",
    "                cols_to_remove.append(col)\n",
    "    input_data.drop(cols_to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_categorical(input_df):\n",
    "    \"\"\"\n",
    "    Removes categorical and only leaves numerical variables in the dataframe\n",
    "    Returns a pandas dataframe\n",
    "    input: pandas dataframe with categorical & numerical data\n",
    "    \"\"\"\n",
    "    cat_columns = list(input_df.select_dtypes(include=['category']).columns)\n",
    "\n",
    "    logging.debug(\"Number of categorical columns: {}\".format(len(cat_columns)))\n",
    "\n",
    "    other_columns = list(input_df.select_dtypes(exclude=['category']).columns)\n",
    "\n",
    "    new_column_order = other_columns\n",
    "    train_df = input_df[new_column_order]\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(input_data):\n",
    "    \"\"\"\n",
    "    Splits data to training & testing sets\n",
    "    Splits columns to input & output for training & testing set respectively\n",
    "    Returns ndarrays\n",
    "    input: a pandas dataframe with a \"target\" column\n",
    "    \"\"\"\n",
    "    # Reorder the columns, categorical go first\n",
    "    train_df = categorical_to_front(input_data)\n",
    "    logging.debug(\n",
    "        \"Categories and label counts: {}\".format(\n",
    "            pformat(categorical_analysis(train_df))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    convert_categories_to_columns(train_df)\n",
    "\n",
    "    logging.debug(train_df.get_dtype_counts())\n",
    "\n",
    "    # Temporary\n",
    "    for col in train_df.select_dtypes(include=['category']).columns:\n",
    "        train_df[col] = train_df[col].astype('category').cat.codes\n",
    "\n",
    "    train_inp = train_df.drop('target', axis=1).as_matrix()\n",
    "    train_out = train_df['target'].as_matrix()\n",
    "\n",
    "    logging.debug(\n",
    "        \"Train 0s/1s: {:.2%} / {:.2%}\".format(\n",
    "            1.0 - np.average(train_out),\n",
    "            np.average(train_out)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_inp,\n",
    "                                                        train_out,\n",
    "                                                        test_size=0.33,\n",
    "                                                        random_state=42)\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_model(x_train, y_train, epochs, batch):\n",
    "    \n",
    "    # learning_rate = .1\n",
    "    # sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    error_fun = Adagrad()\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(output_dim=2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(class_mode='binary', loss='binary_crossentropy', optimizer=error_fun)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto'\n",
    "    )    \n",
    "    \n",
    "    hist = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        nb_epoch=epochs,\n",
    "        batch_size=batch,\n",
    "        validation_split=0.1,\n",
    "        show_accuracy=True,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_model2(x_train, y_train, epochs, batch):\n",
    "    \n",
    "    # learning_rate = .1\n",
    "    # sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    error_fun = Adagrad()\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(512, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(output_dim=2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(class_mode='binary', loss='binary_crossentropy', optimizer=error_fun)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto'\n",
    "    )    \n",
    "    \n",
    "    hist = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        nb_epoch=epochs,\n",
    "        batch_size=batch,\n",
    "        validation_split=0.1,\n",
    "        show_accuracy=True,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epochs_perf_plot(hist):\n",
    "    \"\"\"\n",
    "    Create plot of model performance by epoch\n",
    "    input: nn history object, # epochs\n",
    "    returns bokeh line plot\n",
    "    \"\"\"\n",
    "    epochs = len(hist.history['acc'])\n",
    "    p = figure(title=\"Model Performance (Training Set)\", plot_width=600, plot_height=600)\n",
    "\n",
    "    p.line(x=range(0, epochs), y=hist.history['loss'],\n",
    "           color=\"firebrick\", line_width=4, legend=\"Loss\")\n",
    "    p.line(x=range(0, epochs), y=hist.history['acc'],\n",
    "           color=\"navy\", line_width=4, legend=\"Accuracy\")\n",
    "    \n",
    "    p.legend.orientation = \"bottom_left\"\n",
    "    p.xaxis.axis_label = \"Epoch\"\n",
    "    \n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def undersample(X, class_column):\n",
    "    \"\"\"\n",
    "    Undersamples a dataset to obtain equal number of classes from imbalanced data\n",
    "    input: initial dataset as pandas dataframe, column with class labels as string\n",
    "    \"\"\"\n",
    "    counts = X[class_column].value_counts(ascending=True)\n",
    "    print(\"The frequency of each class: {}.\".format(X[class_column].value_counts(normalize=True)))\n",
    "    classes = pd.unique(X[class_column].ravel())\n",
    "    l = []\n",
    "    for value in classes:\n",
    "        class_indices = X[X[class_column] == value].index\n",
    "        random_index = random.sample(class_indices, counts[0])\n",
    "        l.extend(random_index)\n",
    "    return X.ix[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data & split into testing & training set\n",
    "train_df = load_data(\"train.csv\")\n",
    "x_train, x_test, y_train, y_test = train_test(train_df)\n",
    "\n",
    "logging.debug(\"SHAPES: IN Train [{}], Test [{}]\".format(x_train.shape, x_test.shape))\n",
    "logging.debug(\"SHAPES: OUT Train [{}], Test [{}]\".format(y_train.shape, y_test.shape))\n",
    "\n",
    "# Create NN for 2-layer unidimensional regression\n",
    "batch = 1024\n",
    "epochs = 100\n",
    "\n",
    "model, hist = nn_model(x_train, y_train, epochs, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot model training performance\n",
    "epochs_perf_plot(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test set predictions\n",
    "predicted = model.predict(x_test)\n",
    "logging.info(\"Predicted 0s/1s: {:.2%} {:.2%}\".format(np.average(predicted[:, 0]), np.average(predicted[:, 1])))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, show_accuracy=True, batch_size=batch)\n",
    "\n",
    "print('Test score (log loss): {}'.format(score[0]))\n",
    "print('Test accuracy: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Precision & Recall metrics on test set\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_test[:,1], predicted[:,1])\n",
    "# Plot PRC\n",
    "p = figure(title=\"Model Metrics (PRC)\", plot_width=600, plot_height=600)\n",
    "\n",
    "p.line(x=recall, y=precision, color=\"firebrick\", line_width=4)\n",
    "p.xaxis.axis_label = \"Recall\"\n",
    "p.yaxis.axis_label = \"Precision\"\n",
    "    \n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get true positive rate & false positive rate\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test[:,1], predicted[:,1])\n",
    "# Plot ROC\n",
    "p = figure(title=\"Model Metrics (ROC)\", plot_width=600, plot_height=600)\n",
    "\n",
    "p.line(x=fpr, y=tpr, color=\"navy\", line_width=4)\n",
    "p.xaxis.axis_label = \"False Positive Rate\"\n",
    "p.yaxis.axis_label = \"True Positive Rate\"\n",
    "    \n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute AUC\n",
    "auc = metrics.roc_auc_score(y_test[:,1], predicted[:,1])\n",
    "print(\"The AUC score is: {}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NN with undersampled data (# class 1 == # class 0)\n",
    "data_df = load_data(\"train.csv\")\n",
    "data_df = undersample(data_df, \"target\")\n",
    "x_train, x_test, y_train, y_test = train_test(train_df)\n",
    "\n",
    "logging.debug(\"SHAPES: IN Train [{}], Test [{}]\".format(x_train.shape, x_test.shape))\n",
    "logging.debug(\"SHAPES: OUT Train [{}], Test [{}]\".format(y_train.shape, y_test.shape))\n",
    "\n",
    "model, hist = nn_model(x_train, y_train, epochs, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot undersampled model training performance\n",
    "epochs_perf_plot(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Undersampled Test set predictions\n",
    "predicted = model.predict(x_test)\n",
    "logging.info(\"Predicted 0s/1s: {:.2%} {:.2%}\".format(np.average(predicted[:, 0]), np.average(predicted[:, 1])))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, show_accuracy=True, batch_size=batch)\n",
    "\n",
    "print('Test score (log loss): {}'.format(score[0]))\n",
    "print('Test accuracy: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model3, hist3 = nn_model2(x_train2, y_train2, epochs, batch)\n",
    "\n",
    "# Plot model 3 training performance\n",
    "epochs_perf_plot(hist3)\n",
    "\n",
    "# Test set 3 predictions\n",
    "predicted3 = model3.predict(x_test2)\n",
    "logging.info(\"Predicted 0s/1s: {:.2%} {:.2%}\".format(np.average(predicted3[:, 0]), np.average(predicted3[:, 1])))\n",
    "\n",
    "score3 = model3.evaluate(x_test2, y_test2, show_accuracy=True, batch_size=batch)\n",
    "\n",
    "print('Test score (log loss): {}'.format(score3[0]))\n",
    "print('Test accuracy: {}'.format(score3[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = remove_categorical(load_data(\"train.csv\"))\n",
    "train_df = undersample(train_df, \"target\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test(train_df)\n",
    "\n",
    "logging.debug(\"SHAPES: IN Train [{}], Test [{}]\".format(x_train.shape, x_test.shape))\n",
    "logging.debug(\"SHAPES: OUT Train [{}], Test [{}]\".format(y_train.shape, y_test.shape))\n",
    "\n",
    "model, hist = nn_model2(x_train, y_train, epochs, batch)\n",
    "# Plot model training performance\n",
    "epochs_perf_plot(hist)\n",
    "# Test set predictions\n",
    "predicted = model.predict(x_test)\n",
    "logging.info(\"Predicted 0s/1s: {:.2%} {:.2%}\".format(np.average(predicted[:, 0]), np.average(predicted[:, 1])))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, show_accuracy=True, batch_size=batch)\n",
    "\n",
    "print('Test score (log loss): {}'.format(score[0]))\n",
    "print('Test accuracy: {}'.format(score[1]))\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = load_data(\"train.csv\")\n",
    "train_df = undersample(train_df, \"target\")\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "X = train_df.drop(\"target\", axis=1).drop(\"v22\", axis=1)\n",
    "dv = DictVectorizer()\n",
    "\n",
    "X = dv.fit_transform(X.T.to_dict().values())\n",
    "y = train_df[\"target\"].as_matrix()\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=5)\n",
    "\n",
    "X = lda.fit_transform(X.toarray(), y)\n",
    "\n",
    "train_df = pd.DataFrame(X)\n",
    "train_df[\"target\"] = y\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test(train_df)\n",
    "\n",
    "logging.debug(\"SHAPES: IN Train [{}], Test [{}]\".format(x_train.shape, x_test.shape))\n",
    "logging.debug(\"SHAPES: OUT Train [{}], Test [{}]\".format(y_train.shape, y_test.shape))\n",
    "\n",
    "model, hist = nn_model2(x_train, y_train, epochs, batch)\n",
    "# Plot model training performance\n",
    "epochs_perf_plot(hist)\n",
    "# Test set predictions\n",
    "predicted = model.predict(x_test)\n",
    "logging.info(\"Predicted 0s/1s: {:.2%} {:.2%}\".format(np.average(predicted[:, 0]), np.average(predicted[:, 1])))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, show_accuracy=True, batch_size=batch)\n",
    "\n",
    "print('Test score (log loss): {}'.format(score[0]))\n",
    "print('Test accuracy: {}'.format(score[1]))\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create SVM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "train_df = load_data(\"train.csv\")\n",
    "x_train, x_test, y_train, y_test = train_test(train_df)\n",
    "y_train = y_train[:,1]\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(x_train, y_train)\n",
    "#rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(x_train, y_train)\n",
    "#poly_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(x_train, y_train)\n",
    "#lin_svc = svm.LinearSVC(C=C).fit(X_train, y_train)\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = x_train[:, 0].min() - 1, x_train[:, 0].max() + 1\n",
    "y_min, y_max = x_train[:, 1].min() - 1, x_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# title for the plots\n",
    "titles = ['SVC with linear kernel',\n",
    "          'LinearSVC (linear kernel)',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel']\n",
    "\n",
    "\n",
    "for i, clf in enumerate((svc, lin_svc, rbf_svc, poly_svc)):\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(x_train[:, 0], y_train[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(titles[i])\n",
    "\n",
    "plt.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
